packages=c("tidyverse","data.table","devtools","shiny","shinydashboard","nadiv",
"sommer","agridat","agricolae","desplot")
ipak <- function(pkg){
new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])]
if (length(new.pkg))
install.packages(new.pkg, dependencies = TRUE)
sapply(pkg, require, character.only = TRUE)
}
ipak(packages)
Y
install.packages(c("agridat", "ape", "backports", "BH", "brew", "brio", "broom", "Cairo", "carData", "class", "cli", "clipr", "colorspace", "commonmark", "conquer", "cpp11", "crayon", "DBI", "DEoptimR", "desc", "devtools", "digest", "dplyr", "DT", "dtplyr", "effects", "emmeans", "evaluate", "fansi", "foreach", "forecast", "foreign", "fs", "future", "generics", "gert", "gld", "glue", "gmailr", "gmp", "gower", "HH", "htmlTable", "httpuv", "igraph", "insight", "iterators", "jsonlite", "klaR", "knitr", "lme4", "magrittr", "mapproj", "maptools", "MASS", "mathjaxr", "Matrix", "mclust", "MCMCglmm", "mgcv", "mockery", "multcomp", "nanotime", "nlme", "nloptr", "nnet", "openssl", "parallelly", "parsedate", "pillar", "pkgdown", "pkgload", "progressr", "quantreg", "questionr", "ragg", "randomForest", "Rcpp", "RcppArmadillo", "RcppCCTZ", "readr", "recipes", "remotes", "reticulate", "rgdal", "rlang", "rmarkdown", "rpart", "sessioninfo", "sets", "showtext", "sommer", "spacetime", "spam", "spatial", "stringi", "survival", "systemfonts", "testthat", "tidyr", "tidyselect", "tinytex", "tsibble", "TTR", "usethis", "vroom", "withr", "xfun", "xml2", "yaml"))
#------------------------------------------------------------#
# Chapter 40                                                 #
#------------------------------------------------------------#
library(dplyr)
ls("package:dplyr")
dplyr::filter (iris,Sepal.Length >7)
dplyr::distinct(rbind(iris[1:10,],iris[1:15,]))
dplyr::slice(iris,10:15)
dplyr::sample_n(iris,10)
dplyr::sample_frac(iris,0.1)
dplyr::arrange(iris,Sepal.Length)
dplyr::arrange(iris,desc(Sepal.Length))
summarise(iris,avg=mean(Sepal.Length))
summarise(iris,sum=sum(Sepal.Length))
head(mtcars,20) %>% tail()
dplyr::group_by(iris,Species)
iris %>% group_by(Species) %>% summarise(avg=mean(
Sepal.Width)) %>% arrange(avg)
dplyr::group_by(iris,Species)
iris %>% group_by(Species) %>% summarise(avg=mean(
Sepal.Width)) %>% arrange(avg)
dplyr::mutate(iris,new=Sepal.Length+Petal.Length)
#Connecte
a=data.frame(x1=c("A","B","C"),x2=c(1,2,3))
b=data.frame(x1=c("A","B","D"),x3=c(T,F,T))
dplyr::left_join(a,b,by="x1")
dplyr::full_join(a,b,by="x1")
dplyr::semi_join(a,b,by="x1")
dplyr::anti_join(a,b,by="x1")
first <- slice(mtcars,1:20)
mtcars <- mutate(mtcats,Model=rownames(mtcars))
first <- slice(mtcars,1:20)
second <- slice (mtcars,10:30)
intersect(first, second)
union_all(first, second)
union(first, second)
setdiff(first, second)
setdiff(second, first)
#------------------------------------------------------------#
# Chapter 41                                                 #
#------------------------------------------------------------#
state <- as.data.frame(state.x77[,c("Murder","Population","Illiteracy","Income","Frost")])
fit<- lm (Murder ~ Population+Illiteracy+Income+Frost,data=state)
ls()
Sys.Date()
a <- 1:100
rm(a)
#------------------------------------------------------------#
# Chapter 42                                                 #
#------------------------------------------------------------#
ls("package:base")
par()
length(par())
library(scatterplot3d)
plot(c(1:20),c(seq(1,89,length.out = 20)),type="l",lty=1)
plot(c(1:20),c(seq(1,89,length.out = 20)),type="l",lty=2)
#------------------------------------------------------------#
# Chapter 43                                                 #
#------------------------------------------------------------#
round(rnorm(n=100,mean = 15,sd=2))
x=rnorm(n=100,mean = 15,sd=2)
qqnorm(x)
runif(1)
runif(50)
runif(10)*10
runif(50,min=1,max=100)
dgamma(c(1:9),shape = 2,rate = 1)
set.seed(666)
runif(50)
runif(50)
set.seed(666)
runif(50)
set.seed(666)
runif(50)
#------------------------------------------------------------#
# Chapter 44                                                 #
#------------------------------------------------------------#
myvars <- mtcars[c("mpg", "hp", "wt", "am")]
summary(myvars)
fivenum(myvars$hp)
#Descriptive stats via describe (Hmisc)
install.packages("Hmisc")
install.packages("Hmisc")
library(Hmisc)
#Descriptive stats via stat.desc (pastecs)
install.packages("pastecs")
library(pastecs)
stat.desc(mtcars[myvars])
stat.desc(mtcars,basic = TRUE,desc = TRUE,norm = TRUE)
#Descriptive stats by group with aggregate
library(MASS)
aggregate(Cars93[c("Min.Price","Price","Max.Price","MPG.city")],
by=list(Manufacturer=Cars93$Manufacturer),mean)
aggregate(Cars93[c("Min.Price","Price","Max.Price","MPG.city")],
by=list(Manufacturer=Cars93$Manufacturer),sd)
aggregate(Cars93[c("Min.Price","Price","Max.Price","MPG.city")],
by=list(Origin=Cars93$Origin),mean)
aggregate(Cars93[c("Min.Price","Price","Max.Price","MPG.city")],
by=list(Origin=Cars93$Origin),sd)
View(Cars93)
aggregate(Cars93[c("Min.Price","Price","Max.Price","MPG.city")],
by=list(Origin=Cars93$Origin,Manufacturer=Cars93$Manufacturer),mean)
#Descriptive stats by group via summaryBy
install.packages("doBy")
library(doBy)
library(doBy)
summaryBy(mpg+hp+wt~am, data=mtcars, FUN=mystats)
#Descriptive stats by group via describe.by (psych)
library(psych)
describeBy(mtcars[myvars], list(am=mtcars$am))
#------------------------------------------------------------#
# Chapter 45                                                 #
#------------------------------------------------------------#
# frequency tables
split(mtcars,mtcars$cyl)
split(mtcars,as.factor (mtcars$cyl))
num <- 1:100
cut(num,c(seq(0,100,10)))
cut(mtcars$mpg,c(seq(10,50,10)))
table(mtcars$cyl)
table(mtcars$cyl)
table(cut(mtcars$mpg,c(seq(10,50,10))))
prop.table(table(mtcars$cyl))
prop.table (table(cut(mtcars$mpg,c(seq(10,50,10)))))
prop.table(table(mtcars$cyl))*100
library(vcd)
head(Arthritis)
# one way table
mytable <- with(Arthritis, table(Improved))
mytable  # frequencies
prop.table(mytable) # proportions
prop.table(mytable)*100 # percentages
# two way table
mytable <- table(Arthritis$Treatment,Arthritis$Improved)
with(data = Arthritis,{table(Treatment,Improved)})
mytable <- xtabs(~ Treatment+Improved, data=Arthritis)
mytable # frequencies
margin.table(mytable,1) #row sums
margin.table(mytable, 2) # column sums
margin.table(mytable,1) #row sums
margin.table(mytable, 2) # column sums
prop.table(mytable) # cell proportions
prop.table(mytable, 1) # row proportions
prop.table(mytable, 2) # column proportions
addmargins(mytable) # add row and column sums to table
mytable <- xtabs(~ Treatment+Sex+Improved, data=Arthritis)
mytable
ftable(mytable)
margin.table(mytable, 1)
margin.table(mytable, 2)
margin.table(mytable, 2)
margin.table(mytable, c(1,3))
ftable(prop.table(mytable, c(1,2)))
ftable(addmargins(prop.table(mytable, c(1, 2)), 3))
library(vcd)
mytable <- table(Arthritis$Treatment,Arthritis$Improved)
#mytable <- xtabs(~Treatment+Improved, data=Arthritis)
chisq.test(mytable)
mytable <- table(Arthritis$Treatment,Arthritis$Improved)
chisq.test(mytable)
mytable <- table(Arthritis$Sex,Arthritis$Improved)
chisq.test(mytable)
# Fisher's exact test
mytable <- xtabs(~Treatment+Improved, data=Arthritis)
fisher.test(mytable)
# Chochran-Mantel-Haenszel test
mytable <- xtabs(~Treatment+Improved+Sex, data=Arthritis)
mantelhaen.test(mytable)
cor(state.x77)
cov(state.x77)
#x <- states[,c("Population", "Income", "Illiteracy", "HS Grad")]
x <- state.x77[,c(1,2,3,6)]
#y <- states[,c("Life Exp", "Murder")]
y <- state.x77[,c(4,5)]
cor(x,y)
# partial correlations
install.packages("ggm")
library(ggm)
# partial correlation of population and murder rate, controlling
# for income, illiteracy rate, and HS graduation rate
colnames(state.x77)
pcor(c(1,5,2,3,6), cov(state.x77))
#------------------------------------------------------------#
# Chapter 48                                                 #
#------------------------------------------------------------#
#Testing a correlation coefficient for significance
cor.test(state.x77[,3],state.x77[,5])
#Correlation matrix and tests of significance via corr.test
corr.test(states, use="complete")
library(psych)
corr.test (state.x77)
library(ggm)
x <- pcor(c(1,5,2,3,6),cov(state.x77))
pcor.test(x,3,50)
# t test
library(MASS)
t.test(Prob ~ So, data=UScrime)
#------------------------------------------------------------#
# Chapter 49                                                 #
#------------------------------------------------------------#
ls("package:graphics")
plot (women$height)
plot(women$height,women$weight)
plot(as.factor(women$height))
plot(mtcars$cyl)
plot(as.factor(mtcars$cyl))
plot(as.factor(mtcars$cyl),mtcars$carb)
plot(as.factor(mtcars$carb),as.factor(mtcars$cyl))
plot(as.factor(mtcars$cyl),mtcars$carb)
plot(as.factor(mtcars$carb),as.factor(mtcars$cyl))
plot (women$height~ women$weight)
fit <- lm(height~ weight,data=women)
plot(fit)
methods(plot)
par()
plot(as.factor(mtcars$cyl),col=c("red","green","blue"))
mystats <- function(x,na.omit=FALSE) {
if(na.omit)
x <- x[!is.na(x)]
m <- mean(x)
n <- length(x)
s <- sd(x)
skew <- sum((x-m^3/s^3))/n
kurt <- sum((x-m^4/s^4))/n-3
return(c(n=n,mean=m,stdev=s,skew=skew,kurtosis=kurt))
}
for (i in 1:10) {print ("Hello,World")}
#for ($i=1;$i<=10;$++) {print "hello,world\n";}
i=1;while(i <= 10) {print ("Hello,World");i=i+1;}
i=1;while(i <= 10) {print ("Hello,World");i=i+2;}
score=70;if (score >60 ) {print ("Passwd") } else {print ("Failed")}
ifelse( score >60,print ("Passwd"),print ("Failed"))
#------------------------------------------------------------#
# Chapter 52                                                 #
#------------------------------------------------------------#
women
fit <- lm(weight ~ height, data=women)
summary(fit)
women$weight
？caret
library(caret)
？caret
help(caret)
# install packages (if necessary) and load them
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2,
caret,
ModelMetrics,
randomForest, # 随机森林要用
nnet, # 人工神经网络要用
kernlab, # SVM要用
arm, # 贝叶斯GLM要用
scales)
# set the working directory to the location of the rxnpredict folder
setwd("D:\\虚拟机共享文件\\数据排布\\数据拆分")
# load output table generated by python script
output.table <- read.csv("R\\output_table.csv", header=TRUE)
# scale the descriptor data
output.scaled <- as.data.frame(scale(output.table))
# load user-created yield data (label reactions without yield data as NA)
yield.data <- as.numeric(unlist(read.csv("yields.csv", header=FALSE, stringsAsFactors=FALSE)))
# append the yield data to the output table
output.scaled$yield <- yield.data
pred.scaled1 <- output.scaled[145:288, ] # 萘胺144
pred.scaled2 <- output.scaled[433:576, ] # 对甲苯胺144
pred.scaled3 <- output.scaled[1057:1152, ] # 对碘苯胺96
pred.scaled4 <- output.scaled[1153:1248, ] # 对氯苯胺96
nine.scaled <- rbind(output.scaled[1:144, ], output.scaled[289:432, ], output.scaled[577:1056, ], output.scaled[1249:1632, ])#训练集
#接口
pred.scaled <- pred.scaled1[73:144, ]#后半作为预测
output.scaled <- rbind(nine.scaled, pred.scaled1[1:72, ])#前半参与训练
# 把测试集去杂
pred.scaled <- pred.scaled[!(is.na(pred.scaled$yield)), ]
pred.scaled <- pred.scaled[ , colSums(is.na(pred.scaled)) == 0]
# remove rows where yield=NA and columns containing at least one NA
output.scaled <- output.scaled[!(is.na(output.scaled$yield)), ]
output.scaled <- output.scaled[ , colSums(is.na(output.scaled)) == 0]
rfFit <- readRDS("rds\\2022.5.12\\rfFit-9胺训练集.rds")
# predict yields for test set
rf.pred <- predict(rfFit, test.scaled)
test.scaled <- pred.scaled
# predict yields for test set
rf.pred <- predict(rfFit, test.scaled)
# calculate R^2 and RMSE and display in console
rf.r2 <- cor(rf.pred, test.scaled$yield)
rf.rmse <- rmse(rf.pred, test.scaled$yield)
paste0("R Squared = ", rf.r2, " and RMSE = ", rf.rmse)
# plot calibration plot (saves to R\user_plots\rf_calibration_plot.tiff)-用于微调
df <- data.frame(x = rf.pred,
y = test.scaled$yield)
tiff(filename = "R\\user_plots\\rfFit_萘胺-9胺_预测萘胺_plot.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p1 <- ggplot(df, aes(x = x, y = y)) +
geom_point(alpha = 0.7, colour = "#FF7F50", size=2.1) +
scale_x_continuous(breaks = seq(-10,50,10), lim=c(-10, 50)) +
scale_y_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
labs(x='Predicted Conversions', y='Observed Conversions') +
geom_segment(aes(x=0,xend=50,y=0,yend=50), linetype="dashed") +
geom_smooth(method="lm", se=FALSE,colour = "black")# loess拟合曲线/lm线性回归
plot(p1)
dev.off()
# plot calibration plot (saves to R\user_plots\rf_calibration_plot.tiff)-用于微调
df <- data.frame(x = rf.pred,
y = test.scaled$yield)
tiff(filename = "R\\user_plots\\rfFit_萘胺-9胺_预测萘胺_plot.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p1 <- ggplot(df, aes(x = x, y = y)) +
geom_point(alpha = 0.7, colour = "#FF7F50", size=2.1) +
scale_x_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
scale_y_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
labs(x='Predicted Conversions', y='Observed Conversions') +
geom_segment(aes(x=0,xend=50,y=0,yend=50), linetype="dashed") +
geom_smooth(method="lm", se=FALSE,colour = "black")# loess拟合曲线/lm线性回归
plot(p1)
dev.off()
# uncomment to read in previously trained model (so you don't have to train it every time)
rfFit <- readRDS("rds\\2022.5.12\\rfFit-萘胺-后半.rds")
# predict yields for test set
rf.pred <- predict(rfFit, test.scaled)
# calculate R^2 and RMSE and display in console
rf.r2 <- cor(rf.pred, test.scaled$yield)
rf.rmse <- rmse(rf.pred, test.scaled$yield)
paste0("R Squared = ", rf.r2, " and RMSE = ", rf.rmse)
# plot calibration plot (saves to R\user_plots\rf_calibration_plot.tiff)-用于微调
df <- data.frame(x = rf.pred,
y = test.scaled$yield)
tiff(filename = "R\\user_plots\\rfFit_萘胺-优化_预测萘胺_plot.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p1 <- ggplot(df, aes(x = x, y = y)) +
geom_point(alpha = 0.7, colour = "#FF4500", size=2.1) +
scale_x_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
scale_y_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
labs(x='Predicted Conversions', y='Observed Conversions') +
geom_segment(aes(x=0,xend=50,y=0,yend=50), linetype="dashed") +
geom_smooth(method="lm", se=FALSE,colour = "black")# loess拟合曲线/lm线性回归
plot(p1)
dev.off()
#接口
pred.scaled <- pred.scaled2[73:144, ]#后半作为预测
output.scaled <- rbind(nine.scaled, pred.scaled2[1:72, ])#前半参与训练
# 把测试集去杂
pred.scaled <- pred.scaled[!(is.na(pred.scaled$yield)), ]
pred.scaled <- pred.scaled[ , colSums(is.na(pred.scaled)) == 0]
# remove rows where yield=NA and columns containing at least one NA
output.scaled <- output.scaled[!(is.na(output.scaled$yield)), ]
output.scaled <- output.scaled[ , colSums(is.na(output.scaled)) == 0]
rfFit <- readRDS("rds\\2022.5.12\\rfFit-9胺训练集.rds")
test.scaled <- pred.scaled
# predict yields for test set
rf.pred <- predict(rfFit, test.scaled)
# calculate R^2 and RMSE and display in console
rf.r2 <- cor(rf.pred, test.scaled$yield)
rf.rmse <- rmse(rf.pred, test.scaled$yield)
paste0("R Squared = ", rf.r2, " and RMSE = ", rf.rmse)
#===============================================================================
# plot calibration plot (saves to R\user_plots\rf_calibration_plot.tiff)
df <- data.frame(x = rf.pred,
y = test.scaled$yield)
tiff(filename = "R\\user_plots\\rfFit_对甲苯胺-9胺_预测对甲苯胺_plot.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p1 <- ggplot(df, aes(x = x, y = y)) +
geom_point(alpha = 0.7, colour = "#228B22", size=2.1) +
scale_x_continuous(breaks = seq(0,100,25), lim=c(0, 100)) +
scale_y_continuous(breaks = seq(0,100,25), lim=c(0, 100)) +
labs(x='Predicted Conversions', y='Observed Conversions') +
geom_segment(aes(x=0,xend=100,y=0,yend=100), linetype="dashed") +
geom_smooth(method="lm", se=FALSE,colour = "black")# loess拟合曲线/lm线性回归
plot(p1)
dev.off()
# uncomment to read in previously trained model (so you don't have to train it every time)
rfFit <- readRDS("rds\\2022.5.12\\rfFit-对甲苯胺-后半.rds")
# predict yields for test set
rf.pred <- predict(rfFit, test.scaled)
# calculate R^2 and RMSE and display in console
rf.r2 <- cor(rf.pred, test.scaled$yield)
rf.rmse <- rmse(rf.pred, test.scaled$yield)
paste0("R Squared = ", rf.r2, " and RMSE = ", rf.rmse)
#===============================================================================
# plot calibration plot (saves to R\user_plots\rf_calibration_plot.tiff)
df <- data.frame(x = rf.pred,
y = test.scaled$yield)
tiff(filename = "R\\user_plots\\rfFit_对甲苯胺-优化_预测对甲苯胺_plot.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p1 <- ggplot(df, aes(x = x, y = y)) +
geom_point(alpha = 0.7, colour = "#32CD32", size=2.1) +
scale_x_continuous(breaks = seq(0,100,25), lim=c(0, 100)) +
scale_y_continuous(breaks = seq(0,100,25), lim=c(0, 100)) +
labs(x='Predicted Conversions', y='Observed Conversions') +
geom_segment(aes(x=0,xend=100,y=0,yend=100), linetype="dashed") +
geom_smooth(method="lm", se=FALSE,colour = "black")# loess拟合曲线/lm线性回归
plot(p1)
dev.off()
#接口
# pred.scaled <- pred.scaled2[73:144, ]#后半作为预测
# output.scaled <- rbind(nine.scaled, pred.scaled2[1:72, ])#前半参与训练
pred.scaled <- pred.scaled3[49:96, ]#后半作为预测
output.scaled <- rbind(nine.scaled, pred.scaled3[1:48, ])#前半参与训练
# 把测试集去杂
pred.scaled <- pred.scaled[!(is.na(pred.scaled$yield)), ]
pred.scaled <- pred.scaled[ , colSums(is.na(pred.scaled)) == 0]
# remove rows where yield=NA and columns containing at least one NA
output.scaled <- output.scaled[!(is.na(output.scaled$yield)), ]
output.scaled <- output.scaled[ , colSums(is.na(output.scaled)) == 0]
rfFit <- readRDS("rds\\2022.5.12\\rfFit-9胺训练集.rds")
test.scaled <- pred.scaled
# predict yields for test set
rf.pred <- predict(rfFit, test.scaled)
# calculate R^2 and RMSE and display in console
rf.r2 <- cor(rf.pred, test.scaled$yield)
rf.rmse <- rmse(rf.pred, test.scaled$yield)
paste0("R Squared = ", rf.r2, " and RMSE = ", rf.rmse)
# plot calibration plot (saves to R\user_plots\rf_calibration_plot.tiff)-用于微调
df <- data.frame(x = rf.pred,
y = test.scaled$yield)
tiff(filename = "R\\user_plots\\rfFit_对碘苯胺-9胺_预测对碘苯胺_plot.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p1 <- ggplot(df, aes(x = x, y = y)) +
geom_point(alpha = 0.7, colour = "#4682B4", size=2.1) +
scale_x_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
scale_y_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
labs(x='Predicted Conversions', y='Observed Conversions') +
geom_segment(aes(x=0,xend=50,y=0,yend=50), linetype="dashed") +
geom_smooth(method="lm", se=FALSE,colour = "black")# loess拟合曲线/lm线性回归
plot(p1)
dev.off()
# uncomment to read in previously trained model (so you don't have to train it every time)
rfFit <- readRDS("rds\\2022.5.12\\rfFit-对碘苯胺-后半.rds")
# predict yields for test set
rf.pred <- predict(rfFit, test.scaled)
# calculate R^2 and RMSE and display in console
rf.r2 <- cor(rf.pred, test.scaled$yield)
rf.rmse <- rmse(rf.pred, test.scaled$yield)
paste0("R Squared = ", rf.r2, " and RMSE = ", rf.rmse)
# plot calibration plot (saves to R\user_plots\rf_calibration_plot.tiff)-用于微调
df <- data.frame(x = rf.pred,
y = test.scaled$yield)
tiff(filename = "R\\user_plots\\rfFit_对碘苯胺-优化_预测对碘苯胺_plot.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p1 <- ggplot(df, aes(x = x, y = y)) +
geom_point(alpha = 0.7, colour = "#1E90FF", size=2.1) +
scale_x_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
scale_y_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
labs(x='Predicted Conversions', y='Observed Conversions') +
geom_segment(aes(x=0,xend=50,y=0,yend=50), linetype="dashed") +
geom_smooth(method="lm", se=FALSE,colour = "black")# loess拟合曲线/lm线性回归
plot(p1)
dev.off()
#接口
# pred.scaled <- pred.scaled2[73:144, ]#后半作为预测
# output.scaled <- rbind(nine.scaled, pred.scaled2[1:72, ])#前半参与训练
pred.scaled <- pred.scaled4[49:96, ]#后半作为预测
output.scaled <- rbind(nine.scaled, pred.scaled4[1:48, ])#前半参与训练
# 把测试集去杂
pred.scaled <- pred.scaled[!(is.na(pred.scaled$yield)), ]
pred.scaled <- pred.scaled[ , colSums(is.na(pred.scaled)) == 0]
# remove rows where yield=NA and columns containing at least one NA
output.scaled <- output.scaled[!(is.na(output.scaled$yield)), ]
output.scaled <- output.scaled[ , colSums(is.na(output.scaled)) == 0]
rfFit <- readRDS("rds\\2022.5.12\\rfFit-9胺训练集.rds")
test.scaled <- pred.scaled
# predict yields for test set
rf.pred <- predict(rfFit, test.scaled)
# calculate R^2 and RMSE and display in console
rf.r2 <- cor(rf.pred, test.scaled$yield)
rf.rmse <- rmse(rf.pred, test.scaled$yield)
paste0("R Squared = ", rf.r2, " and RMSE = ", rf.rmse)
# plot calibration plot (saves to R\user_plots\rf_calibration_plot.tiff)-用于微调
df <- data.frame(x = rf.pred,
y = test.scaled$yield)
tiff(filename = "R\\user_plots\\rfFit_对氯苯胺-9胺_预测对氯苯胺_plot.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p1 <- ggplot(df, aes(x = x, y = y)) +
geom_point(alpha = 0.7, colour = "#800080", size=2.1) +
scale_x_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
scale_y_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
labs(x='Predicted Conversions', y='Observed Conversions') +
geom_segment(aes(x=0,xend=50,y=0,yend=50), linetype="dashed") +
geom_smooth(method="lm", se=FALSE,colour = "black")# loess拟合曲线/lm线性回归
plot(p1)
dev.off()
# uncomment to read in previously trained model (so you don't have to train it every time)
rfFit <- readRDS("rds\\2022.5.12\\rfFit-对氯苯胺-后半.rds")
# predict yields for test set
rf.pred <- predict(rfFit, test.scaled)
# calculate R^2 and RMSE and display in console
rf.r2 <- cor(rf.pred, test.scaled$yield)
rf.rmse <- rmse(rf.pred, test.scaled$yield)
paste0("R Squared = ", rf.r2, " and RMSE = ", rf.rmse)
# plot calibration plot (saves to R\user_plots\rf_calibration_plot.tiff)-用于微调
df <- data.frame(x = rf.pred,
y = test.scaled$yield)
tiff(filename = "R\\user_plots\\rfFit_对氯苯胺-优化_预测对氯苯胺_plot.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p1 <- ggplot(df, aes(x = x, y = y)) +
geom_point(alpha = 0.7, colour = "#9932CC", size=2.1) +
scale_x_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
scale_y_continuous(breaks = seq(0,50,10), lim=c(0, 50)) +
labs(x='Predicted Conversions', y='Observed Conversions') +
geom_segment(aes(x=0,xend=50,y=0,yend=50), linetype="dashed") +
geom_smooth(method="lm", se=FALSE,colour = "black")# loess拟合曲线/lm线性回归
plot(p1)
dev.off()
