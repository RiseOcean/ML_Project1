# install packages (if necessary) and load them
if (!require("pacman")) install.packages("pacman")
pacman::p_load(ggplot2, 
               caret,
               ModelMetrics,
               randomForest, # 随机森林要用
               nnet, # 人工神经网络要用
               kernlab, # SVM要用
               arm, # 贝叶斯GLM要用
               scales)

# set the working directory to the location of the rxnpredict folder
setwd("D:\\虚拟机共享文件\\数据排布\\数据拆分")


# ============================================================================
# Load descriptor and yield data and prepare data for modeling
# ============================================================================

# load output table generated by python script
output.table <- read.csv("R\\output_table.csv", header=TRUE)

# scale the descriptor data
output.scaled <- as.data.frame(scale(output.table))

# load user-created yield data (label reactions without yield data as NA)
yield.data <- as.numeric(unlist(read.csv("yields.csv", header=FALSE, stringsAsFactors=FALSE)))

# append the yield data to the output table
output.scaled$yield <- yield.data


# remove rows where yield=NA and columns containing at least one NA
output.scaled <- output.scaled[!(is.na(output.scaled$yield)), ]
output.scaled <- output.scaled[ , colSums(is.na(output.scaled)) == 0]


# ============================================================================
# Split data and train random forest model
# ============================================================================

# Split into training and test set (70/30)
set.seed(1084)
size <- round(0.50*nrow(output.scaled))
training <- sample(nrow(output.scaled), size=size, replace=FALSE)
training.scaled <- output.scaled[training, ]
test.scaled <- output.scaled[-training, ]

# 10-fold cross-validation
train_control <- trainControl(method="cv", number=10, savePredictions=TRUE)

# train the random forest model
set.seed(8915)
rfFit <- train(yield ~ ., data=training.scaled, trControl=train_control, method="rf", importance=TRUE)
saveRDS(rfFit, "rds\\2022.5.12\\rfFit-50-9an_train.rds")

# uncomment to read in previously trained model (so you don't have to train it every time)
# rfFit <- readRDS("rds\\2022.5.12\\rfFit-50-9an_train.rds")

# ============================================================================
# Calculate R^2 and RMSE using test set and generate calibration plot
# ============================================================================

# predict yields for test set
rf.pred <- predict(rfFit, test.scaled)

# calculate R^2 and RMSE and display in console
rf.r2 <- cor(rf.pred, test.scaled$yield)
rf.rmse <- rmse(rf.pred, test.scaled$yield)
paste0("R Squared = ", rf.r2, " and RMSE = ", rf.rmse)


#===============================================================================
# plot calibration plot (saves to R\user_plots\rf_calibration_plot.tiff)
df <- data.frame(x = rf.pred,
                 y = test.scaled$yield)
tiff(filename = "R\\user_plots\\rfFit_对甲苯胺-优化_预测对甲苯胺_plot.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p1 <- ggplot(df, aes(x = x, y = y)) +
  geom_point(alpha = 0.7, colour = "#32CD32", size=2.1) + 
  scale_x_continuous(breaks = seq(0,100,25), lim=c(0, 100)) +
  scale_y_continuous(breaks = seq(0,100,25), lim=c(0, 100)) +
  labs(x='Predicted Conversions', y='Observed Conversions') +  
  geom_segment(aes(x=0,xend=100,y=0,yend=100), linetype="dashed") +
  geom_smooth(method="lm", se=FALSE,colour = "black")# loess拟合曲线/lm线性回归
plot(p1)
dev.off()
#===============================================================================

# ============================================================================
# Create variable importance plot
# ============================================================================

# read in variable importance from trained random forest model
rf_imp <- importance(rfFit$finalModel)
rf.imp.df <- cbind(as.data.frame(rf_imp), names(rf_imp[, 1]))
colnames(rf.imp.df)[1] <- "IncMSE"
colnames(rf.imp.df)[3] <- "descriptor"

# for descriptor names, replace "_" with " " and "." with "*"
rf.imp.df$descriptor <- gsub("_", " ", rf.imp.df$descriptor)
rf.imp.df$descriptor <- gsub("[.]", "*", rf.imp.df$descriptor)

# capitalize descriptor names
simpleCap <- function(x) {
    s <- strsplit(x, " ")[[1]]
    paste(toupper(substring(s, 1, 1)), substring(s, 2),
          sep="", collapse=" ")
}
rf.imp.df$descriptor <- sapply(rf.imp.df$descriptor, simpleCap)

# plot variable importance (saves to R\user_plots\rf_variable_importance.png)
# USER: change '10' on next line to modify minimum cutoff for IncMSE
tiff(filename = "R\\user_plots\\rf_variable_importance-70trainset.tiff",compression="lzw",units="in",res=1000,pointsize=8,height=4,width=5)
p2 <- ggplot(rf.imp.df[rf.imp.df$IncMSE>11, ], aes(x=reorder(descriptor, IncMSE), y=IncMSE)) +
    geom_bar(stat="identity") +
    scale_y_continuous(labels = comma) +
    labs(x="", y="Increase in Mean Squared Error (%)") + 
    coord_flip()
plot(p2)
dev.off()